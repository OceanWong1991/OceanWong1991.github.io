<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>OceanWong</title>

  <meta name="author" content="XueZhong Wong">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Ocean Wong</name>
                  </p>
                  <p>
                   I am a senior staff Algorithm Engineer at <a href="https://www.invo.cn/">Invo Auto Technology Co., Ltd</a> in Beijing, where I work on computer vision and machine learning. 
                  </p>
                  <p>
                    I am passionate about Artificial Intelligence, Self-driving, data analysis and computer vision. During my free time, I enjoy participating in Kaggle competitions, and got competitions expert tier.
                  </p>
                  <!-- <p>
                   I got my B.S. degree in Information and Computing Science in June 2015 at HBAU. now, Now, I am looking for positions for Master degree.
                  </p>
 -->
                  <p style="text-align:center">
                    <a href="mailto:OceanWong1991@gmail.com">Email</a> &nbsp|&nbsp
                  <!--  <a href="data/CV_OceanWong.pdf">CV</a> &nbsp|&nbsp   -->
                    <a href="https://www.kaggle.com/oceanwong">Kaggle</a> &nbsp|&nbsp
                    <a href="https://leetcode-cn.com/u/oceanwong1991/">Leetcode</a> &nbsp|&nbsp
                    <a href="https://github.com/OceanWong1991">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile2-circle.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile2-circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Profile</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>8+ years of experience in Machine Learning, Deep Learning, and Computer Vision </li>
                <li>Research experience both in the industry and academic settings. </li>
                <li>Strong communication, and teamwork skills.</li>
                <li>Quick learning abilities and result-oriented approach. </li>
                <li>IELTS 7.0, College English Test Band 6(CET 6), Proficiency in English. </li>
              </ul>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Experience & Education</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>2022 - Present <a href="https://www.invo.cn/">Invo Auto Technology Co., Ltd.</a> Senior Algorithm Engineer. </li>
                <li>2021 - 2022 University of British Columbia, AI Researcher</li>
                <li>2015 - 2021, <a href="http://www.shuangjisha.com/">Beijing Sphyrna Technology Co., Ltd.</a> Artificial Intelligence Algorithm Engineer </li>
                <li>2011 - 2015, Heilongjiang Bayi Agricultural University. B.Sc. in Information and Computing Science </li>
              </ul>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Awards And Honors</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>[Dec 2019] Competition Expert Tier. TOP 0.67%(1072/159,193) </li>
                <li>[Dec 2019] Solo Silver Medal. <a href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles">Lyft 3D Object Detection for Autonomous Vehicles</a> Kaggle; PB Top 6%(30/546)  </li>
                <li>[Oct 2019] <a href="https://www.kaggle.com/c/severstal-steel-defect-detection">Severstal: Steel Defect Detection</a> Kaggle; LB Top 7%(182/2427); PB Top 13%(301/2427) </li>
                <li>[Sep 2019] Solo Silver Medal <a href="https://www.kaggle.com/c/aptos2019-blindness-detection">APTOS 2019 Blindness Detection Competition</a> Kaggle; PB Top 2%(55/2928). </li>
                <li>[Apr 2014] First Class Professional Scholarship</li>
                <li>[Sep 2013] 2nd Prize as team leader, China Undergraduate Mathematical Contest in Modeling(CUMCM), China</li>
                <li>[May 2013] 1st Prize as team leader, Northeast Undergraduate Mathematical Contest in Modeling, HeiLongJing, China </li>
              </ul>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/psd.gif" style="width:320px;height:350px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>BEV Parking Slot Detection</papertitle>
                  </a>
                  <p>
                    This project aims to refactor and optimize a parking slot detection system that started in 2019. The original project has the following problems: The code has serious coupling, redundancy, chaos and other issues, making it difficult to maintain and extend. The underlying architecture design is unreasonable, causing the upper layer logic to frequently patch the underlying bugs. The tracking module‚Äôs tracking algorithm and matching algorithm cannot meet the new scenario‚Äôs requirements and need to be redesigned.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Refactor the entire project, follow good coding standards, and improve the code‚Äôs readability, maintainability and extensibility.</li>
                  <li>Redesign the underlying architecture, ensure its stability and correctness, and reduce the burden of the upper layer logic.</li>
                  <li>Redesign the tracking module based on vehicle kinematics using trajectory prediction, and improve its performance and accuracy in new scenarios.</li>
                  <li>Modify the logic of the parking space generation module, perform corner fusion first and then generate parking spaces, and improve the quality and quantity of parking spaces.</li>
                  <li>Optimize the simulation module, add a sensor fusion module, solve the problem of sensor timestamp alignment, and improve the credibility of the simulation results.</li>
                </td>
              </tr>
          </table>


          <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
              <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/combined_navi.gif" style="width:320px;height:180px;"></div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a>
                  <papertitle>Combined Navigation</papertitle>
                </a>
                <p>
                  Combined navigation is a sophisticated navigation system that integrates information from multiple sensors, including Inertial Measurement Unit (IMU), Global Navigation Satellite System (GNSS), and odometer sensors. The system employs the Error State Kalman Filter (ESKF) for state estimation and error correction. 
                </p>
                <p>The key tasks of this combined navigation system are:</p>
                

                <li>1. IMU Initialization: The system initiates the IMU by estimating the sensor measurement noise and zero biases. This involves calibrating and setting up the IMU to ensure accurate and reliable measurements.</li>
                <li>2. GNSS Data Processing: The system processes data from GNSS receivers.The GNSS data is transformed into the UTM (Universal Transverse Mercator) coordinate system for consistent and accurate positioning.</li>
                <li>3. ESKF Implementation: The main focus of the system is on implementing the Error State Kalman Filter (ESKF) for state estimation.
                  The ESKF is a recursive algorithm that continuously updates the system's state estimates based on sensor measurements and system dynamics.
                  It corrects errors and improves the accuracy of the navigation solution by considering the error states in the estimation.</li>
              </td>
            </tr>
        </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/LD.gif" style="width:320px;height:350px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>BEV Lane Detection</papertitle>
                  </a>
                  <p>
                    BEV Lane Detection is a project that aims to detect the lane markings and the intersection type of a road using a bird's eye view (BEV) image.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Feature extraction: The BEV image is segmented into binary images using a thresholding method. Then, a feature extraction method is applied to the binary images to obtain the edge features of the lane markings.</li>
                  <li>Clustering algorithm: The edge features are grouped into clusters. The clusters represent the candidate lane segments that are further filtered based on their orientation and length.</li>
                  <li>Fitting algorithm: A straight line is fitted to each cluster using a least squares method. The parameters of the line are used to calculate the slope and the intercept of the lane segment. </li>
                  <li>Backtracking algorithm: A backtracking algorithm is used to find the optimal solution space for the lane detection problem. The algorithm starts from the bottom of the image and searches for the best pair of left and right lane segments that satisfy some constraints, such as distance, angle, and continuity. The algorithm then moves up to the next row of clusters and repeats the process until it reaches the top of the image or no valid pair is found. </li>
                  <li>Tracking algorithm:The track estimation algorithm is based on the principle of dead reckoning, which is a way of calculating the position and orientation of a moving object by using its previous state and motion information. Tracking can handle complex road conditions, such as occlusions, shadows, and noise. </li>
                  <li>Intersection type determination: Based on the information of the detected lane segments, such as their number, position, orientation, and slope, the intersection type of the road is determined. The possible intersection types are: straight, left turn, right turn, crossroad, T-junction, or unknown. </li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/sensor_fusion.jpeg" style="width:320px;height:180px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Sensor Fusion</papertitle>
                  </a>
                  <p>
                    The purpose of this project is to use multi-sensor data for vehicle environment perception.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Data parsing and alignment: Parse the data from four video signals and CAN signals, extract the video frames and vehicle state information, and align the data according to the timestamps, ensuring the data synchronization.</li>
                  <li>Design and implement a millimeter-wave radar and camera fusion scheme, achieve spatial and temporal synchronization of the two sensors, perform point cloud clustering on the millimeter-wave radar data, use UKF to track multiple targets, associate targets, and thus achieve detection and identification of obstacles around the vehicle1.</li>
                </td>
              </tr>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/video_masking.gif" style="width:300px;height:225px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Video de-identification</papertitle>
                  </a>
                  <p>
                    Video de-identification project is a project that uses deep learning techniques to detect and eliminate sensitive information such as license plates and faces in the car-end data, aiming to protect the privacy and security of the information subjects.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Data automatic annotation: A data automatic annotation pipeline was established, which used a large model to pre-annotate the raw data, and then performed manual verification and correction, improving the annotation efficiency and quality..</li>
                  <li>Data mining and hard sample analysis: A set of data mining and hard sample analysis tools chain was designed, which performed operations such as statistics, filtering, clustering, visualization, etc. on the data, discovered and solved the problems and difficulties in the data, and enhanced the diversity and representativeness of the data.</li>
                  <li>Car-end real-time detection model: A lightweight car-end real-time detection model was designed, which used a fish's eye view image as input, combined with attention mechanism and multi-scale feature fusion techniques, achieved efficient detection of sensitive information such as license plates, faces, etc. </li>
                  <li>Car-end detection performance evaluation: The detection performance of the car-end detection model in different scenarios was evaluated, using indicators such as accuracy, as well as visualization methods, to show the performance and advantages of the model. Finally, the car-end face detection accuracy reached 91.62%, and the license plate detection precision reached 90.52%.</li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/bsd.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Blind Spot Detection System</papertitle>
                  </a>
                  <p>
                    The BSD system detects other vehicles and pedestrians in the blind area, and warns to help the driver to drive safely. Provides the driver with visual and audial warning when parking or lane changes
                  </p>
                  <p>Brief introduction: Blind Spot Detection system</p>

                  <li>Designed clean and analysis fisheye image data system(label image data is a boring and laborious job; I designed an auto label system, and the Efficiency increased by 90% ).</li>
                  <li>Designed and trained our detection model on our fisheye image data.</li>
                  <li>Optimized our detection model, we wanted to Run algorithms in real-time on low-end chips(Allwinner T5). So I need to trim our model, reduced Model parameters from 1.22M to 0.3M, reduced Model calculation from 1.2 BFlops to 0.139 BFlops, increased model mAP from 90% to 91%  </li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/rover.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Rover robot</papertitle>
                  </a>

                  <p>
                    Rover robot uses senses(radar, IMU, and Odometry) , which enable robot build maps, avoid obstacles automatically and cruise at fixed points
                  </p>
                  
                  <p>Brief introduction: Rover robot</p>

                  <li>Designed robot chassis.</li>
                  <li>Designed Unicycle Robot Model.</li>
                  <li>Used Odometry to Track Robot Movement.</li>
                  <li>Deployed google-cartographer, ros-navigation algorithm on rover robot.</li>
                  <br>
                  
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/dsm.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Driver Status Monitor System</papertitle>
                  </a>
                  <p>
                    Driver Status Monitor uses a camera to capture an image of the driver‚Äôs face and establishes the driver‚Äôs condition based on visual analysis. It detects carelessness, distraction and drowsiness, Smoking, Phone  and then alerts the driver of any potential danger.
                  </p>
                  <p>Brief introduction: Driver Status Monitor</p>

                  <li>Designed driver face, key points and behaviour detetion neural networks.</li>
                  <li>Implemented driver face, key points and behaviour detetion neural network by caffe.</li>
                  <li>Tained a big neural network to label and clean our driver image data.</li>
                  <li>Used our labeled data to train our neural networks.</li>
                  <li>Optimized train Strategies(implemented Online Hard Example Mining algorithm), Accuracy increased from 98% to 99.3%.</li>
                  <li>Optimized detection Strategies(used Optical flow algorithm), speed increased from 5HZ to 26HZ; Increased 5 times, so we can run our model on embeded system(Rock Chip RK3399).</li>

                  <br>
                  
                </td>
              </tr>
          </table>

          

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Other Passions</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>I enjoy travelling around the world, talking with people who came from different culture and world, and learn about different aspects of our world. </li>
                <li>I like solving problems and helping others; during work time, I would like to help my colleagues with software problems and algorithm bugs. </li>
                <li>I also enjoy reading books, especially Biographies and investment books</li>
                <li>I'm really into wild nature, I would like to try my best to protect our planet. buy less packaging products, Do not use plastic bags as far as I can. </li>
              </ul>
            </tbody>
          </table> -->


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template modified from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
