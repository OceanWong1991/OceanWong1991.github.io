<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>OceanWong</title>

  <meta name="author" content="XueZhong Wong">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Ocean Wong</name>
                  </p>
                  <p>
                   I am a senior staff Algorithm Engineer at <a href="https://www.invo.cn/">Invo Auto Technology Co., Ltd</a> in Beijing, where I work on computer vision and machine learning. 
                  </p>
                  <p>
                    I am passionate about Artificial Intelligence, Self-driving, data analysis and computer vision. During my free time, I enjoy participating in Kaggle competitions, and got competitions expert tier.
                  </p>
                  <!-- <p>
                   I got my B.S. degree in Information and Computing Science in June 2015 at HBAU. now, Now, I am looking for positions for Master degree.
                  </p>
 -->
                  <p style="text-align:center">
                    <a href="mailto:OceanWong1991@gmail.com">Email</a> &nbsp|&nbsp
                  <!--  <a href="data/CV_OceanWong.pdf">CV</a> &nbsp|&nbsp   -->
                    <a href="https://www.kaggle.com/oceanwong">Kaggle</a> &nbsp|&nbsp
                    <a href="https://leetcode-cn.com/u/oceanwong1991/">Leetcode</a> &nbsp|&nbsp
                    <a href="https://github.com/OceanWong1991">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile2-circle.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile2-circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>8+ years of experience in Machine Learning, Deep Learning, and Computer Vision </li>
                <li>Research experience both in the industry and academic settings. </li>
                <li>Strong communication, and teamwork skills.</li>
                <li>Quick learning abilities and result-oriented approach. </li>
              </ul>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Awards And Honors</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>[Dec 2019] Competition Expert Tier. TOP 0.67%(1072/159,193) </li>
                <li>[Dec 2019] Solo Silver Medal. <a href="https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles">Lyft 3D Object Detection for Autonomous Vehicles</a> Kaggle; PB Top 6%(30/546)  </li>
                <li>[Oct 2019] <a href="https://www.kaggle.com/c/severstal-steel-defect-detection">Severstal: Steel Defect Detection</a> Kaggle; LB Top 7%(182/2427); PB Top 13%(301/2427) </li>
                <li>[Sep 2019] Solo Silver Medal <a href="https://www.kaggle.com/c/aptos2019-blindness-detection">APTOS 2019 Blindness Detection Competition</a> Kaggle; PB Top 2%(55/2928). </li>
                <li>[Apr 2014] First Class Professional Scholarship</li>
                <li>[Sep 2013] 2nd Prize as team leader, China Undergraduate Mathematical Contest in Modeling(CUMCM), China</li>
                <li>[May 2013] 1st Prize as team leader, Northeast Undergraduate Mathematical Contest in Modeling, HeiLongJing, China </li>
              </ul>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/LD.gif" style="width:320px;height:350px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>BEV Lane Detection</papertitle>
                  </a>
                  <p>
                    BEV Lane Detection is a project that aims to detect the lane markings and the intersection type of a road using a bird's eye view (BEV) image.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Feature extraction: The BEV image is segmented into binary images using a thresholding method. Then, a feature extraction method is applied to the binary images to obtain the edge features of the lane markings.</li>
                  <li>Clustering algorithm: The edge features are grouped into clusters. The clusters represent the candidate lane segments that are further filtered based on their orientation and length.</li>
                  <li>Fitting algorithm: A straight line is fitted to each cluster using a least squares method. The parameters of the line are used to calculate the slope and the intercept of the lane segment. </li>
                  <li>Backtracking algorithm: A backtracking algorithm is used to find the optimal solution space for the lane detection problem. The algorithm starts from the bottom of the image and searches for the best pair of left and right lane segments that satisfy some constraints, such as distance, angle, and continuity. The algorithm then moves up to the next row of clusters and repeats the process until it reaches the top of the image or no valid pair is found. </li>
                  <li>Tracking algorithm:The track estimation algorithm is based on the principle of dead reckoning, which is a way of calculating the position and orientation of a moving object by using its previous state and motion information. Tarking can handle complex road conditions, such as occlusions, shadows, and noise. </li>
                  <li>Intersection type determination: Based on the information of the detected lane segments, such as their number, position, orientation, and slope, the intersection type of the road is determined. The possible intersection types are: straight, left turn, right turn, crossroad, T-junction, or unknown. </li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/sensor_fusion.jpeg" style="width:320px;height:180px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Sensor Fusion</papertitle>
                  </a>
                  <p>
                    The purpose of this project is to use multi-sensor data for vehicle environment perception.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Data parsing and alignment: Parse the four-channel video signals and CAN signals, extract the video frames and vehicle state information, and align the data according to the timestamps, ensuring the data synchronization. This part of the data is used for the simulation system, simulating the real road scenarios and vehicle behaviors.</li>
                  <li>Lidar and camera fusion: Use Kalman filter to fuse the lidar and camera data, use point cloud projection and image bounding box methods to obtain accurate distance and image category, and use Kalman filter to track the objects, thus achieving the detection and recognition of obstacles around the vehicle. This part of the data is used for the real-time system, providing the vehicle with environment perception capability.</li>
                  <li>Lidar and radar fusion: Use extended Kalman filter to fuse the lidar and radar data, improving the estimation accuracy of the distance and speed of the obstacles. This part of the data is used for the auxiliary system, providing the vehicle with safety warning capability. </li>
                </td>
              </tr>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/video_masking.gif" style="width:300px;height:225px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Video de-identification</papertitle>
                  </a>
                  <p>
                    Video de-identification project is a project that uses deep learning techniques to detect and eliminate sensitive information such as license plates and faces in the car-end data, aiming to protect the privacy and security of the information subjects.
                  </p>
                  <p>The main work of the project includes the following aspects:</p>

                  <li>Data automatic annotation: A data automatic annotation pipeline was established, which used a large model to pre-annotate the raw data, and then performed manual verification and correction, improving the annotation efficiency and quality..</li>
                  <li>Data mining and hard sample analysis: A set of data mining and hard sample analysis tools chain was designed, which performed operations such as statistics, filtering, clustering, visualization, etc. on the data, discovered and solved the problems and difficulties in the data, and enhanced the diversity and representativeness of the data.</li>
                  <li>Car-end real-time detection model: A lightweight car-end real-time detection model was designed, which used a fish's eye view image as input, combined with attention mechanism and multi-scale feature fusion techniques, achieved efficient detection of sensitive information such as license plates, faces, etc. </li>
                  <li>Car-end detection performance evaluation: The detection performance of the car-end detection model in different scenarios was evaluated, using indicators such as accuracy, as well as visualization methods, to show the performance and advantages of the model. Finally, the car-end face detection accuracy reached 91.62%, and the license plate detection precision reached 90.52%.</li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/bsd.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Blind Spot Detection System</papertitle>
                  </a>
                  <p>
                    The BSD system detects other vehicles and pedestrians in the blind area, and warns to help the driver to drive safely. Provides the driver with visual and audial warning when parking or lane changes
                  </p>
                  <p>Brief introduction: Blind Spot Detection system</p>

                  <li>Designed clean and analysis fisheye image data system(label image data is a boring and laborious job; I designed an auto label system, and the Efficiency increased by 90% ).</li>
                  <li>Designed and trained our detection model on our fisheye image data.</li>
                  <li>Optimized our detection model, we wanted to Run algorithms in real-time on low-end chips(Allwinner T5). So I need to trim our model, reduced Model parameters from 1.22M to 0.3M, reduced Model calculation from 1.2 BFlops to 0.139 BFlops, increased model mAP from 90% to 91%  </li>
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/rover.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Rover robot</papertitle>
                  </a>

                  <p>
                    Rover robot uses senses(radar, IMU, and Odometry) , which enable robot build maps, avoid obstacles automatically and cruise at fixed points
                  </p>
                  
                  <p>Brief introduction: Rover robot</p>

                  <li>Designed robot chassis.</li>
                  <li>Designed Unicycle Robot Model.</li>
                  <li>Used Odometry to Track Robot Movement.</li>
                  <li>Deployed google-cartographer, ros-navigation algorithm on rover robot.</li>
                  <br>
                  
                </td>
              </tr>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:left"><div><img src="images/dsm.gif" style="width:265px;height:135px;"></div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a>
                    <papertitle>Driver Status Monitor System</papertitle>
                  </a>
                  <p>
                    Driver Status Monitor uses a camera to capture an image of the driver‚Äôs face and establishes the driver‚Äôs condition based on visual analysis. It detects carelessness, distraction and drowsiness, Smoking, Phone  and then alerts the driver of any potential danger.
                  </p>
                  <p>Brief introduction: Driver Status Monitor</p>

                  <li>Designed driver face, key points and behaviour detetion neural networks.</li>
                  <li>Implemented driver face, key points and behaviour detetion neural network by caffe.</li>
                  <li>Tained a big neural network to label and clean our driver image data.</li>
                  <li>Used our labeled data to train our neural networks.</li>
                  <li>Optimized train Strategies(implemented Online Hard Example Mining algorithm), Accuracy increased from 98% to 99.3%.</li>
                  <li>Optimized detection Strategies(used Optical flow algorithm), speed increased from 5HZ to 26HZ; Increased 5 times, so we can run our model on embeded system(Rock Chip RK3399).</li>

                  <br>
                  
                </td>
              </tr>
          </table>

          

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Other Passions</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>I enjoy travelling around the world, talking with people who came from different culture and world, and learn about different aspects of our world. </li>
                <li>I like solving problems and helping others; during work time, I would like to help my colleagues with software problems and algorithm bugs. </li>
                <li>I also enjoy reading books, especially Biographies and investment books</li>
                <li>I'm really into wild nature, I would like to try my best to protect our planet. buy less packaging products, Do not use plastic bags as far as I can. </li>
              </ul>
            </tbody>
          </table> -->


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template modified from <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
